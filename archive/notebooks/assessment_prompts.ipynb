{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25202af8-5f20-4839-800e-6797379b948b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b645ba19-5acf-4b48-b111-5db6f3bd0444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ad64e47-264c-4fd0-958b-a0e0923e8c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"/Users/harshabommana/Work/HyperVerge/HVA/sensai/sensai-pocs/local_data/subjects/pandas/roadmap.json\") as file_handle:\n",
    "    subject_roadmap = json.load(file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c101c6-e0cd-4081-80bb-d3a19dcc3ff4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_topics(subject_roadmap):\n",
    "\n",
    "    all_topics = []\n",
    "    for topic in subject_roadmap:\n",
    "        all_topics.append(topic[\"topic_name\"])\n",
    "\n",
    "    return all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee7466b-4b03-4e75-85f9-5fe0738386aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_topics = get_topics(subject_roadmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33dba7e3-d88a-40a3-bc77-38d7a08bd060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subject = \"Pandas for Data Analysis\"\n",
    "topic = \"Creating, Reading and Writing\"\n",
    "bloom_level = \"Knowledge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad59472d-7662-4907-b586-d623fb680fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas for Data Analysis ['Creating, Reading and Writing', 'Indexing, Selecting & Assigning', 'Summary Functions and Maps', 'Grouping and Sorting', 'Data Types and Missing Values', 'Renaming and Combining'] Creating, Reading and Writing Knowledge\n"
     ]
    }
   ],
   "source": [
    "print(subject, all_topics, topic, bloom_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff340a12-ae7d-4949-a426-d8a43ef4fbf3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f2e87-7bad-4f34-96e7-28d0263f97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_chat_question_completion(chat_question_completion):\n",
    "    \n",
    "    \n",
    "    prompt = chat_question_completion + \"\\n\\n\"\n",
    "    prompt += \"\"\"Parse this into the following JSON Format:\n",
    "\n",
    "[\n",
    "    {\n",
    "        \"question\": str\n",
    "    }\n",
    "]\n",
    "\n",
    "JSON:\"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "      model=\"text-davinci-003\",\n",
    "      prompt=prompt,\n",
    "      max_tokens=512,\n",
    "      temperature=0\n",
    "    )\n",
    "    questions_json_str = response[\"choices\"][0][\"text\"]\n",
    "    questions_json = json.loads(questions_json_str)\n",
    "    questions = [q_dict[\"question\"] for q_dict in questions_json]\n",
    "    \n",
    "    return questions\n",
    "\n",
    "def evaluate_answer(question, answer):\n",
    "    prompt = f\"\"\"Evaluate the following answer to the question \"{question}\":\n",
    "\n",
    "\"{answer}\"\n",
    "\n",
    "Output either \"Yes\" or \"No\".\"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\", prompt=prompt, max_tokens=32, temperature=0\n",
    "    )\n",
    "\n",
    "    if \"yes\" in response[\"choices\"][0][\"text\"].lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abbb404-da9f-436d-8c83-a9aae1bddab6",
   "metadata": {},
   "source": [
    "# V0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2afc8cd-ab0e-4dd3-8483-cb7f8f0d3b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_system_prompt(subject, topics, topic):\n",
    "    \n",
    "    system_prompt = \"\"\n",
    "    system_prompt += \"You are EducationGPT, a very helpful educational asssistant. You are very good at course planning, design and analysis. You can understand what is the best way to ensure a learner has understood some key concepts in any subject and can create effective course content and assessments to facilitate this\\n\\n\"\n",
    "    system_prompt += f\"The subject of the course is \\\"{subject}\\\"\\n\"\n",
    "    system_prompt += \"The topics for this course are:\\n\"\n",
    "    \n",
    "    for topic_text in topics:\n",
    "        system_prompt += f\"- {topic_text}\\n\"\n",
    "        \n",
    "    system_prompt += f\"\\nThe topic we are currently focusing on is \\\"{topic}\\\"\\n\\n\"\n",
    "    system_prompt += \"\"\"Bloom's Taxonomy is a very useful tool for guiding assessment creation for any subject. We want to create assessments that target the following level of Bloom's Taxonomy:\n",
    "\n",
    "Knowledge:\n",
    "This is related to remembering or recalling the information. Generally, the verbs used in this level are: Define, list, name, recall, state, recognize, and so forth. Specifically for computer science subjects, a learner's competency at this level can be assessed by asking them to define a particular method, recall syntax, recognize a specific concept present in some code, etc.\n",
    "\n",
    "Comprehension:\n",
    "This is related to recalling and interpreting facts. Commonly used verbs at this level are: summarize, understand, comprehend, explain, generalize, interpret, predict, summarize, and translate. Learners should understand the function and behaviors of each structure. Specifically for computer science subjects, a learner's competency at this level can be assessed by asking them to translate an algorithm from one form to another, explaining how a certain code snippet works, translating a code snippet into another language, etc.\"\"\"\n",
    "    \n",
    "    return system_prompt\n",
    "\n",
    "def parse_questions(chat_text):\n",
    "    \n",
    "    prompt = chat_text + \"\\n\\n\"\n",
    "    prompt += \"\"\"Parse these questions and criteria into a JSON with the following format:\n",
    "[\n",
    "    {\n",
    "        \"question\": str,\n",
    "        \"criteria\": [str, str, str...]\n",
    "    }\n",
    "]\n",
    "\n",
    "JSON:\"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"text-davinci-003\",\n",
    "        prompt = prompt,\n",
    "        max_tokens = 1024,\n",
    "        temperature = 0\n",
    "    )\n",
    "    \n",
    "    questions_json_str = response[\"choices\"][0][\"text\"].strip()\n",
    "    questions_json = json.loads(questions_json_str)\n",
    "    \n",
    "    return questions_json\n",
    "\n",
    "\n",
    "def get_questions(subject, all_topics, topic, bloom_level):\n",
    "    \n",
    "    system_prompt = create_system_prompt(subject, topic, all_topics)\n",
    "    \n",
    "    question_message = f\"Create assessment questions for the subject \\\"{subject}\\\" and the topic \\\"{topic}\\\" with respect to the \\\"{bloom_level}\\\" level of Bloom's Taxonomy. Here are some guidelines to follow which creating the assessment questions:\\n- Make sure you are creating the questions within this particular topic and not the other topics.\\n- The question needs to promote effortful thinking and establish that the learner has really understood the underlying concepts.\\n- If there are any code snippets in the question annotate them with ```.\\n- Frame questions such that the required answer can be written in very few words.\\n- The assessments will be open book in nature so ask questions that can really test understanding of concepts even if the learners are allowed to refer to educational material.\\n\\nCreate 5 questions.\"\n",
    "    criteria_message = \"For each of these questions, provide detailed and objective evaluation criteria which will be used to evaluate the learner's answers. Here are some guidelines to follow while creating the criteria:\\n- This will be in the form of a list of around 4-5 criteria for each question.\\n- These criteria should approximately be of equal importance.\\n- These criteria should effectively describe levels of expected performance for the assessment.\\n- Describe demonstrable behavior; do not describe the learner.\\n- Avoid vague terms that are open to subjective interpretation such as \\\"critical,\\\" \\\"appropriate,\\\" \\\"excellent\\\" and \\\"analytical.\\\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": system_prompt + \"\\n\\n\" + question_message}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "    chat_question_completion = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    messages.append({\"role\": \"assistant\", \"content\": chat_question_completion})\n",
    "    messages.append({\"role\": \"user\", \"content\": criteria_message})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature = 0.5\n",
    "    )\n",
    "    chat_criteria_completion = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    questions = parse_questions(chat_question_completion + \"\\n\" + chat_criteria_completion)\n",
    "    \n",
    "    return questions\n",
    "\n",
    "\n",
    "def parse_evaluation(criteria_evaluation_text):\n",
    "    \n",
    "    prompt = criteria_evaluation_text + \"\\n\\n\"\n",
    "    prompt += \"\"\"Parse this into a JSON with the following format:\n",
    "[\n",
    "    {\n",
    "        \"evaluation_result\": bool,\n",
    "        \"reason\": str\n",
    "    }\n",
    "]\n",
    "\n",
    "JSON:\"\"\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\", prompt = prompt, max_tokens = 1024, temperature = 0\n",
    "    )\n",
    "    criteria_evaluation_json_str = response[\"choices\"][0][\"text\"].strip()\n",
    "    criteria_evaluation_result = json.loads(criteria_evaluation_json_str)\n",
    "    \n",
    "    return criteria_evaluation_result\n",
    "    \n",
    "    \n",
    "def evaluate_answer(question, answer, subject, topic):\n",
    "    \n",
    "    question_text = question[\"question\"]\n",
    "    criteria_list = question[\"criteria\"]\n",
    "    \n",
    "    prompt = f\"You are an expert in the subject \\\"{subject}\\\" and are currently facilitating an online learning program teaching this subject. The topic we are currently focusing on is \\\"{topic}\\\"\\n\\n.\"\n",
    "    prompt += f\"Question: {question_text}\\nStudent Answer: {answer}\\n\\n\"\n",
    "    prompt += \"Evaluation Criteria:\\n\"\n",
    "    for criteria_idx, criteria_text in enumerate(criteria_list):\n",
    "        prompt += f\"{criteria_idx + 1}. {criteria_text}\\n\"\n",
    "    prompt += \"\\n\"\n",
    "    prompt += \"For each of the provided evaluation criteria, mention if the student's answer has satisfied it, and why.\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\", prompt=prompt, max_tokens=512, temperature=0.5\n",
    "    )\n",
    "    \n",
    "    criteria_evaluation_text = response[\"choices\"][0][\"text\"].strip()\n",
    "    criteria_evaluation_result = parse_evaluation(criteria_evaluation_text)\n",
    "    \n",
    "    prompt += \"\\n\" + criteria_evaluation_text + \"\\n\"\n",
    "    prompt += \"Provide some feedback for the student for this question. Make sure the feedback is as clear, objective and actionable as possible.\"\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        model = \"text-davinci-003\", prompt=prompt, max_tokens=512, temperature=0.5\n",
    "    )\n",
    "    \n",
    "    feedback_text = response[\"choices\"][0][\"text\"].strip()\n",
    "    \n",
    "    return criteria_evaluation_result, feedback_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9dd264-fc0a-48a6-a032-c932889182bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = get_questions(subject, all_topics, topic, bloom_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2496e597-d581-4ff5-b6d4-a3043f84585e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is the function of the ```pd.read_csv()``` method in Pandas?',\n",
       "  'criteria': ['The answer must mention that the ```pd.read_csv()``` method is used to read CSV files into a Pandas DataFrame.',\n",
       "   'The answer must mention that this method has several optional parameters such as ```delimiter```, ```header```, and ```index_col``` which allow the user to customize the import process.',\n",
       "   'The answer must demonstrate an understanding of how to use this method to read a CSV file into a Pandas DataFrame.',\n",
       "   'The answer must not contain any irrelevant or incorrect information.',\n",
       "   'The answer must be concise and clearly written.']},\n",
       " {'question': 'Define the term \"DataFrame\" in Pandas.',\n",
       "  'criteria': ['The answer must define a DataFrame as a two-dimensional labeled data structure with columns of potentially different types.',\n",
       "   'The answer must mention that a DataFrame can be thought of as a spreadsheet or SQL table.',\n",
       "   'The answer must demonstrate an understanding of how to create a DataFrame using Pandas.',\n",
       "   'The answer must not contain any irrelevant or incorrect information.',\n",
       "   'The answer must be concise and clearly written.']},\n",
       " {'question': 'What is the difference between the ```to_csv()``` and ```to_excel()``` methods in Pandas?',\n",
       "  'criteria': ['The answer must mention that the ```to_csv()``` method is used to write a DataFrame to a CSV file, while ```to_excel()``` is used to write a DataFrame to an Excel file.',\n",
       "   'The answer must mention that the ```to_excel()``` method requires the user to have the ```openpyxl``` module installed.',\n",
       "   'The answer must demonstrate an understanding of how to use these methods to write a DataFrame to a file.',\n",
       "   'The answer must not contain any irrelevant or incorrect information.',\n",
       "   'The answer must be concise and clearly written.']},\n",
       " {'question': 'State the purpose of the ```pd.DataFrame()``` constructor in Pandas.',\n",
       "  'criteria': ['The answer must mention that the ```pd.DataFrame()``` constructor is used to create a new DataFrame object.',\n",
       "   'The answer must mention that this constructor has several optional parameters such as ```data```, ```index```, and ```columns``` which allow the user to customize the DataFrame.',\n",
       "   'The answer must demonstrate an understanding of how to use this constructor to create a DataFrame.',\n",
       "   'The answer must not contain any irrelevant or incorrect information.',\n",
       "   'The answer must be concise and clearly written.']},\n",
       " {'question': 'What is the syntax to write a Pandas DataFrame to a SQL database using the ```to_sql()``` method?',\n",
       "  'criteria': ['The answer must mention that the ```to_sql()``` method is used to write a DataFrame to a SQL database.',\n",
       "   'The answer must mention that the syntax for this method includes the name of the database table to be created and the connection object to the database.',\n",
       "   'The answer must demonstrate an understanding of how to use this method to write a DataFrame to a SQL database.',\n",
       "   'The answer must not contain any irrelevant or incorrect information.',\n",
       "   'The answer must be concise and clearly written.']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35f26b6c-592f-4281-8caf-9a868dd9d94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is the function of the ```pd.read_csv()``` method in Pandas?', 'criteria': ['The answer must mention that the ```pd.read_csv()``` method is used to read CSV files into a Pandas DataFrame.', 'The answer must mention that this method has several optional parameters such as ```delimiter```, ```header```, and ```index_col``` which allow the user to customize the import process.', 'The answer must demonstrate an understanding of how to use this method to read a CSV file into a Pandas DataFrame.', 'The answer must not contain any irrelevant or incorrect information.', 'The answer must be concise and clearly written.']}\n",
      "pd.read_csv() is used to read csv files present on the disk. We can use pd.read_csv(path) to read the csv file present at that path.\n"
     ]
    }
   ],
   "source": [
    "question = questions[0]\n",
    "print(question)\n",
    "answer = \"pd.read_csv() is used to read csv files present on the disk. We can use pd.read_csv(path) to read the csv file present at that path.\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29b47bc8-3b29-47d5-9e1a-1a86cb233845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criteria_evaluation, feedback_text = evaluate_answer(question, answer, subject, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e35a248-2e3e-44d6-b542-feb1166fbf19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The answer must mention that the ```pd.read_csv()``` method is used to read CSV files into a Pandas DataFrame.',\n",
       " 'The answer must mention that this method has several optional parameters such as ```delimiter```, ```header```, and ```index_col``` which allow the user to customize the import process.',\n",
       " 'The answer must demonstrate an understanding of how to use this method to read a CSV file into a Pandas DataFrame.',\n",
       " 'The answer must not contain any irrelevant or incorrect information.',\n",
       " 'The answer must be concise and clearly written.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question[\"criteria\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac5d9d4d-1864-47fe-ba32-faca6bcb4d46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'evaluation_result': True, 'reason': 'mentions that the pd.read_csv() method is used to read CSV files into a Pandas DataFrame'}, {'evaluation_result': False, 'reason': 'does not mention any of the optional parameters such as delimiter, header, and index_col'}, {'evaluation_result': False, 'reason': 'does not demonstrate an understanding of how to use this method to read a CSV file into a Pandas DataFrame'}, {'evaluation_result': True, 'reason': 'does not contain any irrelevant or incorrect information'}, {'evaluation_result': True, 'reason': 'is concise and clearly written'}]\n"
     ]
    }
   ],
   "source": [
    "print(criteria_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9659b43-1a75-4eae-b083-2bf7a3db64c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your answer is accurate, but it could be improved by including more information about the optional parameters of the ```pd.read_csv()``` method. Additionally, it would be beneficial to provide an example of how to use this method to read a CSV file into a Pandas DataFrame.\n"
     ]
    }
   ],
   "source": [
    "print(feedback_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d133af-8622-44fc-9818-922d9f68805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "For each of these questions, provide detailed and objective evaluation criteria which will be used to evaluate the learner's answers. Here are some guidelines to follow while creating the criteria:\n",
    "- This will be in the form of a list of around 4-5 criteria for each question.\n",
    "- These criteria should approximately be of equal importance.\n",
    "- These criteria should effectively describe levels of expected performance for the assessment.\n",
    "- Describe demonstrable behavior; do not describe the student.\n",
    "- Avoid vague terms that are open to subjective interpretation such as “critical,” “appropriate,” “excellent” and “analytical.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef88e32-163f-4239-b560-f40525294d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Create assessment questions for the subject \"Pandas for Data Analysis\" and the topic \"Creating, Reading and Writing\" with respect to the \"Knowledge\" level of Bloom's Taxonomy. Here are some guidelines to follow while creating the assessment questions:\n",
    "- Make sure you are creating the questions within this particular topic and not the other topics.\n",
    "- The question needs to promote effortful thinking and establish that the learner has really understood the underlying concepts.\n",
    "- If there are any code snippets in the question annotate them with ```.\n",
    "- Frame questions such that the required answer can be written in very few words.\n",
    "- The assessments will be open book in nature so ask questions that can really test understanding of concepts even if the learners are allowed to refer to educational material.\n",
    "\n",
    "Create 5 questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
